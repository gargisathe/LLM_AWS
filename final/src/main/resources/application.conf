conversationalAgent {
  # URL for the microservice that sends requests to Lambda
  microserviceUrl = "http://3.26.104.98:8082/invokeLambda"

  # Timeout for request handling
  requestTimeout = 5000ms
}
aws {
  s3 {
    bucket = "llmb"
    word2VecModelKey = "word2vecModel.zip"
    neuralModelKey = "neuralmodel.zip"
    tokenIdToWordMapKey = "E_M.txt"
  }
}

local {
  paths {
    word2VecModelPath = "/tmp/word2vecModel.zip"
    neuralModelPath = "/tmp/neuralmodel.zip"
    tokenIdToWordMapPath = "/tmp/A_EM.txt"
  }
}

# HTTP Server Configuration
http {
  host = "0.0.0.0"
  port = 8081
}

# API Gateway URL for invoking Lambda
apiGateway {
  url = "https://5am3tl8xa0.execute-api.ap-southeast-2.amazonaws.com/invoke/LambdaFunction"
}

# gRPC + Proto Configuration
grpc {
  mediaType = "application/grpc+proto"
  charset = "UTF-8"
}

# Logging Configuration
logging {
  enabled = true
}

server {
  host = "0.0.0.0"
  port = 8080
}

grpc {
  content-type = "application/grpc+proto"
}


# TinyLlama Interaction Configuration

# Ollama host and model
tinyllama {
  host = "http://localhost:11434"
  model = "tinyllama:latest"
}
